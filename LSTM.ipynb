{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98bc8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Bidirectional, LSTM, Dense, RepeatVector, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76c9b5",
   "metadata": {},
   "source": [
    "# Read in Sentinel A, B data; Read in in-situ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126b4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Sentinel A data\n",
    "sentinel_data_A = pd.read_csv(\"data/Sentinel_3A_water_level_Version0.csv\")\n",
    "sentinel_data_A = sentinel_data_A.rename(\n",
    "    columns={\n",
    "        \"Date (YYYYMMDD)\" : \"date\",\n",
    "        \"Lake_name\" : \"lake_name\",\n",
    "        \"Latitude\" : \"latitude\",\n",
    "        \"Longitude\" : \"longitude\",\n",
    "        \"Relaive_orbit\" : \"relative_orbit\",\n",
    "        \"Lake water level (m)\" : \"lake_water_level\"\n",
    "    }\n",
    ")\n",
    "# Convert date to date time.\n",
    "sentinel_data_A.loc[:, \"date\"] = pd.to_datetime(sentinel_data_A.loc[:, \"date\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbb5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Sentinel B data\n",
    "sentinel_data_B = pd.read_csv(\"data/Sentinel_3B_water_level_Version0.csv\")\n",
    "\n",
    "sentinel_data_B = sentinel_data_B.rename(\n",
    "    columns={\n",
    "        \"Date (YYYYMMDD)\" : \"date\",\n",
    "        \"Lake_name\" : \"lake_name\",\n",
    "        \"Latitude\" : \"latitude\",\n",
    "        \"Longitude\" : \"longitude\",\n",
    "        \"Relaive_orbit\" : \"relative_orbit\",\n",
    "        \"Lake water level (m)\" : \"lake_water_level\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert date to date time.\n",
    "sentinel_data_B.loc[:, \"date\"] = pd.to_datetime(sentinel_data_B.loc[:, \"date\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382422c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "sentinel_data = pd.concat([sentinel_data_A, sentinel_data_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11134e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate Lake Winnipeg data\n",
    "lake_winnipeg = sentinel_data[\n",
    "    sentinel_data[\"lake_name\"] == \"Winnipeg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed03b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in-situ data\n",
    "lake_winnipeg_in_situ = pd.read_csv(\"./data/WinnipegLake_at_GeorgeIsland.csv\")\n",
    "lake_winnipeg_in_situ = lake_winnipeg_in_situ.rename(\n",
    "    columns={\n",
    "        \"Date\" : \"date\",\n",
    "        \"Value (m)\" : \"in_situ_lake_water_level\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33408a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to date time.\n",
    "lake_winnipeg_in_situ.loc[:, \"date\"] = pd.to_datetime(lake_winnipeg_in_situ.loc[:, \"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Select only date and in_situ_lake_water_level\n",
    "lake_winnipeg_in_situ = lake_winnipeg_in_situ[[\"date\", \"in_situ_lake_water_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc46a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data on date\n",
    "lake_winnipeg = lake_winnipeg.merge(lake_winnipeg_in_situ, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39dffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_winnipeg = lake_winnipeg.loc[\n",
    "    pd.notnull(lake_winnipeg[\"in_situ_lake_water_level\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55513eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lake_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>relative_orbit</th>\n",
       "      <th>lake_water_level</th>\n",
       "      <th>in_situ_lake_water_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79726</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.840506</td>\n",
       "      <td>-98.627263</td>\n",
       "      <td>112</td>\n",
       "      <td>217.231253</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79727</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.837662</td>\n",
       "      <td>-98.628729</td>\n",
       "      <td>112</td>\n",
       "      <td>216.901952</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79728</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.834818</td>\n",
       "      <td>-98.630195</td>\n",
       "      <td>112</td>\n",
       "      <td>216.901451</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79729</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.831974</td>\n",
       "      <td>-98.631661</td>\n",
       "      <td>112</td>\n",
       "      <td>217.006650</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79730</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.829131</td>\n",
       "      <td>-98.633126</td>\n",
       "      <td>112</td>\n",
       "      <td>216.928148</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date lake_name   latitude  longitude  relative_orbit  \\\n",
       "79726 2019-01-10  Winnipeg  53.840506 -98.627263             112   \n",
       "79727 2019-01-10  Winnipeg  53.837662 -98.628729             112   \n",
       "79728 2019-01-10  Winnipeg  53.834818 -98.630195             112   \n",
       "79729 2019-01-10  Winnipeg  53.831974 -98.631661             112   \n",
       "79730 2019-01-10  Winnipeg  53.829131 -98.633126             112   \n",
       "\n",
       "       lake_water_level  in_situ_lake_water_level  \n",
       "79726        217.231253                   217.155  \n",
       "79727        216.901952                   217.155  \n",
       "79728        216.901451                   217.155  \n",
       "79729        217.006650                   217.155  \n",
       "79730        216.928148                   217.155  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_winnipeg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f697d",
   "metadata": {},
   "source": [
    "# Find the length of the longest track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e61eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lake_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21</th>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-22</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lake_name\n",
       "date                 \n",
       "2019-01-01        369\n",
       "2019-01-05        156\n",
       "2019-01-08        705\n",
       "2019-01-09        272\n",
       "2019-01-10        282\n",
       "...               ...\n",
       "2021-05-14        367\n",
       "2021-05-18        156\n",
       "2021-05-21        704\n",
       "2021-05-22        272\n",
       "2021-05-25        778\n",
       "\n",
       "[250 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the longest track\n",
    "counts = lake_winnipeg.groupby(\"date\").agg(\n",
    "    {\n",
    "        \"lake_name\" : \"count\"\n",
    "    }\n",
    ")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc6bb30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(counts[\"lake_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb7e0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_track_length = max(counts[\"lake_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec4c28f",
   "metadata": {},
   "source": [
    "# Adjust the data so every day has max_track_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0498a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=lake_winnipeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "99a365e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://stackoverflow.com/questions/68803947/how-do-i-make-each-group-within-a-dataframe-the-same-size\n",
    "df = df.set_index([\"date\", df.groupby(\"date\").cumcount()])\n",
    "index = pd.MultiIndex.from_product(df.index.levels, names=df.index.names)\n",
    "output = df.reindex(index, fill_value=np.nan).reset_index(level=1, drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a7e672d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% complete\n",
      "4.02% complete\n",
      "8.03% complete\n",
      "12.05% complete\n",
      "16.06% complete\n",
      "20.08% complete\n",
      "24.10% complete\n",
      "28.11% complete\n",
      "32.13% complete\n",
      "36.14% complete\n",
      "40.16% complete\n",
      "44.18% complete\n",
      "48.19% complete\n",
      "52.21% complete\n",
      "56.22% complete\n",
      "60.24% complete\n",
      "64.26% complete\n",
      "68.27% complete\n",
      "72.29% complete\n",
      "76.31% complete\n",
      "80.32% complete\n",
      "84.34% complete\n",
      "88.35% complete\n",
      "92.37% complete\n",
      "96.39% complete\n",
      "100.00% complete\n"
     ]
    }
   ],
   "source": [
    "# Fill in the rest of the data frame with the first entry for each date for a column\n",
    "def populate_data_frame_with_first_entry_on_each_date(column):\n",
    "    output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        column\n",
    "    ] = output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        column\n",
    "    ].iloc[0]\n",
    "\n",
    "    \n",
    "number_of_dates = len(pd.unique(output[\"date\"]))\n",
    "\n",
    "for j, date in enumerate(pd.unique(output[\"date\"])):\n",
    "    # We padded the array with NaNs to make each date have 920 data points\n",
    "    # Find out how many non-NaNs we have. This represents the last real data\n",
    "    # point on each day. E.g. on 2019-01-01 there are 369 real data points\n",
    "    last_non_null_index = output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        \"lake_water_level\"\n",
    "    ].count()\n",
    "\n",
    "    # Get the lake water level on each day as a numpy array\n",
    "    lake_water_level = np.array(\n",
    "        output.loc[\n",
    "            output[\"date\"] == date,\n",
    "            \"lake_water_level\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get the mean and standard deviation of the non-NaN data on each day\n",
    "    mean_lake_water_level = np.mean(lake_water_level[0:last_non_null_index])\n",
    "    std_lake_water_level = np.std(lake_water_level[0:last_non_null_index])\n",
    "\n",
    "    # We are going to populate the NaNs with a randomly sampled array\n",
    "    # with the right standard deviation and mean\n",
    "    filling_array = np.random.normal(\n",
    "        loc=mean_lake_water_level,\n",
    "        scale=std_lake_water_level,\n",
    "        size=max_track_length - last_non_null_index # e.g. 920 - 369 = 551\n",
    "    )\n",
    "\n",
    "    # Fill the NaNs\n",
    "    lake_water_level[last_non_null_index:max_track_length] = filling_array\n",
    "\n",
    "    # Put back into the data frame\n",
    "    output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        \"lake_water_level\"\n",
    "    ] = lake_water_level\n",
    "\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"relative_orbit\")\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"in_situ_lake_water_level\")\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"lake_name\")\n",
    "    \n",
    "    if j % 10 == 0 or j == number_of_dates - 1:\n",
    "        percentage_complete = j/(number_of_dates - 1) * 100.\n",
    "        print(\"%0.02f%% complete\"%(percentage_complete))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4fef8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data frame to csv\n",
    "output.to_csv(\"./processed/imputed_sentinel_a_b_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dad96536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68ed5f4",
   "metadata": {},
   "source": [
    "# Prepare test/train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d7471822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = output.iloc[0:200*920]\n",
    "df_test = output.iloc[201*920::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b0eebb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(datain, timestep):\n",
    "    # Get the lake water levels as numpy arrays\n",
    "    lake_water_levels = np.array(datain[\"lake_water_level\"])\n",
    "    in_situ_lake_water_levels = np.array(datain[\"in_situ_lake_water_level\"])\n",
    "    \n",
    "    # Get the number of unique dates. For e.g. in our training data, it's 200.\n",
    "    number_of_dates = len(pd.unique(datain[\"date\"]))\n",
    "    \n",
    "    # Number of windows we can fit into the data\n",
    "    number_of_windows = number_of_dates - (2 * timestep) + 1\n",
    "    \n",
    "    # Sliding window across the data\n",
    "    for d in range(0, number_of_dates - (2 * timestep) + 1):\n",
    "        X_start = d * max_track_length # Starting index\n",
    "        X_end = (d + timestep) * max_track_length # Finishing index\n",
    "        \n",
    "        Y = (d + np.arange(timestep)) * max_track_length # Indices for getting in-situ data\n",
    "        \n",
    "        if d==0:\n",
    "            X_comb = lake_water_levels[X_start:X_end]\n",
    "            Y_comb = in_situ_lake_water_levels[Y]\n",
    "        else:\n",
    "            X_comb = np.append(X_comb, lake_water_levels[X_start:X_end])\n",
    "            Y_comb = np.append(Y_comb, in_situ_lake_water_levels[Y])\n",
    "\n",
    "    # Reshape input and target arrays\n",
    "    X_out = np.reshape(X_comb, (number_of_windows, timestep*max_track_length, 1))\n",
    "    Y_out = np.reshape(Y_comb, (number_of_windows, timestep, 1))\n",
    "    return X_out, Y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "da206846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = prepare_data(datain=df_train, timestep=5)\n",
    "X_test, Y_test = prepare_data(datain=df_test, timestep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d3781063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5, 1)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2f4c7440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*920"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b99b3",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c25df172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM\n",
    "model = Sequential(name=\"LSTM-Model\")\n",
    "model.add(\n",
    "    Input(\n",
    "        shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        name=\"Input-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(\n",
    "            units=32,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=False,\n",
    "        ),\n",
    "        name=\"Hidden-LSTM-Encoder-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    RepeatVector(\n",
    "        Y_train.shape[1],\n",
    "        name=\"Repeat-Vector-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(\n",
    "            units=32,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=False,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        name=\"Hidden-LSTM-Decoder-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=1,\n",
    "            activation=\"linear\"\n",
    "        ),\n",
    "        name=\"Output-Layer\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c97c9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"MeanSquaredError\", \"MeanAbsoluteError\"],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    "    steps_per_execution=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ade13c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "# I ran the model overnight and saved the result to My_LSTM\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     Y_train,\n",
    "#     batch_size=1,\n",
    "#     epochs=1000,\n",
    "#     verbose=1,\n",
    "#     callbacks=None,\n",
    "#     validation_split=0.2,\n",
    "#     # validation_data=(X_test, Y_test)\n",
    "#     shuffle=True,\n",
    "#     class_weight=None,\n",
    "#     sample_weight=None,\n",
    "#     initial_epoch=0,\n",
    "#     steps_per_epoch=None,\n",
    "#     validation_steps=None,\n",
    "#     validation_batch_size=None,\n",
    "#     validation_freq=100,\n",
    "#     max_queue_size=10,\n",
    "#     workers=1,\n",
    "#     use_multiprocessing=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8bbb7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('My_LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "659fa8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 144ms/step\n",
      "2/2 [==============================] - 0s 96ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict results on training data\n",
    "pred_train = model.predict(X_train)\n",
    "# Predict results on test data\n",
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68816bf8",
   "metadata": {},
   "source": [
    "# Simplification: take the median on each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c365cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_output = output.groupby(\"date\").agg(\n",
    "    {\n",
    "        \"date\" : \"first\",\n",
    "        \"lake_name\" : \"first\",\n",
    "        \"relative_orbit\" : \"first\",\n",
    "        \"lake_water_level\" : \"median\",\n",
    "        \"in_situ_lake_water_level\" : \"first\"\n",
    "        # Drop lat/long since it varies for each point\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd88a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
