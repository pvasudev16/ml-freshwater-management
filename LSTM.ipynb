{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98bc8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import Input\n",
    "from keras.layers import Bidirectional, LSTM, Dense, RepeatVector, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5846a5",
   "metadata": {},
   "source": [
    "# Read in Sentinel A, B data; Read in in-situ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126b4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Sentinel A data\n",
    "sentinel_data_A = pd.read_csv(\"data/Sentinel_3A_water_level_Version0.csv\")\n",
    "sentinel_data_A = sentinel_data_A.rename(\n",
    "    columns={\n",
    "        \"Date (YYYYMMDD)\" : \"date\",\n",
    "        \"Lake_name\" : \"lake_name\",\n",
    "        \"Latitude\" : \"latitude\",\n",
    "        \"Longitude\" : \"longitude\",\n",
    "        \"Relaive_orbit\" : \"relative_orbit\",\n",
    "        \"Lake water level (m)\" : \"lake_water_level\"\n",
    "    }\n",
    ")\n",
    "# Convert date to date time.\n",
    "sentinel_data_A.loc[:, \"date\"] = pd.to_datetime(sentinel_data_A.loc[:, \"date\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ad12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Sentinel B data\n",
    "sentinel_data_B = pd.read_csv(\"data/Sentinel_3B_water_level_Version0.csv\")\n",
    "\n",
    "sentinel_data_B = sentinel_data_B.rename(\n",
    "    columns={\n",
    "        \"Date (YYYYMMDD)\" : \"date\",\n",
    "        \"Lake_name\" : \"lake_name\",\n",
    "        \"Latitude\" : \"latitude\",\n",
    "        \"Longitude\" : \"longitude\",\n",
    "        \"Relaive_orbit\" : \"relative_orbit\",\n",
    "        \"Lake water level (m)\" : \"lake_water_level\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert date to date time.\n",
    "sentinel_data_B.loc[:, \"date\"] = pd.to_datetime(sentinel_data_B.loc[:, \"date\"], format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f21de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "sentinel_data = pd.concat([sentinel_data_A, sentinel_data_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11134e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate Lake Winnipeg data\n",
    "lake_winnipeg = sentinel_data[\n",
    "    sentinel_data[\"lake_name\"] == \"Winnipeg\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4ba5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in-situ data\n",
    "lake_winnipeg_in_situ = pd.read_csv(\"./data/WinnipegLake_at_GeorgeIsland.csv\")\n",
    "lake_winnipeg_in_situ = lake_winnipeg_in_situ.rename(\n",
    "    columns={\n",
    "        \"Date\" : \"date\",\n",
    "        \"Value (m)\" : \"in_situ_lake_water_level\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f62d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to date time.\n",
    "lake_winnipeg_in_situ.loc[:, \"date\"] = pd.to_datetime(lake_winnipeg_in_situ.loc[:, \"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Select only date and in_situ_lake_water_level\n",
    "lake_winnipeg_in_situ = lake_winnipeg_in_situ[[\"date\", \"in_situ_lake_water_level\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc08b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data on date\n",
    "lake_winnipeg = lake_winnipeg.merge(lake_winnipeg_in_situ, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b945d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_winnipeg = lake_winnipeg.loc[\n",
    "    pd.notnull(lake_winnipeg[\"in_situ_lake_water_level\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec59cb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lake_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>relative_orbit</th>\n",
       "      <th>lake_water_level</th>\n",
       "      <th>in_situ_lake_water_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79726</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.840506</td>\n",
       "      <td>-98.627263</td>\n",
       "      <td>112</td>\n",
       "      <td>217.231253</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79727</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.837662</td>\n",
       "      <td>-98.628729</td>\n",
       "      <td>112</td>\n",
       "      <td>216.901952</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79728</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.834818</td>\n",
       "      <td>-98.630195</td>\n",
       "      <td>112</td>\n",
       "      <td>216.901451</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79729</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.831974</td>\n",
       "      <td>-98.631661</td>\n",
       "      <td>112</td>\n",
       "      <td>217.006650</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79730</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>53.829131</td>\n",
       "      <td>-98.633126</td>\n",
       "      <td>112</td>\n",
       "      <td>216.928148</td>\n",
       "      <td>217.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date lake_name   latitude  longitude  relative_orbit  \\\n",
       "79726 2019-01-10  Winnipeg  53.840506 -98.627263             112   \n",
       "79727 2019-01-10  Winnipeg  53.837662 -98.628729             112   \n",
       "79728 2019-01-10  Winnipeg  53.834818 -98.630195             112   \n",
       "79729 2019-01-10  Winnipeg  53.831974 -98.631661             112   \n",
       "79730 2019-01-10  Winnipeg  53.829131 -98.633126             112   \n",
       "\n",
       "       lake_water_level  in_situ_lake_water_level  \n",
       "79726        217.231253                   217.155  \n",
       "79727        216.901952                   217.155  \n",
       "79728        216.901451                   217.155  \n",
       "79729        217.006650                   217.155  \n",
       "79730        216.928148                   217.155  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_winnipeg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cae9a",
   "metadata": {},
   "source": [
    "# Find the length of the longest track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d92abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lake_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-10</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21</th>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-22</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lake_name\n",
       "date                 \n",
       "2019-01-01        369\n",
       "2019-01-05        156\n",
       "2019-01-08        705\n",
       "2019-01-09        272\n",
       "2019-01-10        282\n",
       "...               ...\n",
       "2021-05-14        367\n",
       "2021-05-18        156\n",
       "2021-05-21        704\n",
       "2021-05-22        272\n",
       "2021-05-25        778\n",
       "\n",
       "[250 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the longest track\n",
    "counts = lake_winnipeg.groupby(\"date\").agg(\n",
    "    {\n",
    "        \"lake_name\" : \"count\"\n",
    "    }\n",
    ")\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487b08b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(counts[\"lake_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d447ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_track_length = max(counts[\"lake_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1aa236",
   "metadata": {},
   "source": [
    "# Adjust the data so every day has max_track_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "434f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=lake_winnipeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4323a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://stackoverflow.com/questions/68803947/how-do-i-make-each-group-within-a-dataframe-the-same-size\n",
    "df = df.set_index([\"date\", df.groupby(\"date\").cumcount()])\n",
    "index = pd.MultiIndex.from_product(df.index.levels, names=df.index.names)\n",
    "output = df.reindex(index, fill_value=np.nan).reset_index(level=1, drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "529ce3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% complete\n",
      "4.02% complete\n",
      "8.03% complete\n",
      "12.05% complete\n",
      "16.06% complete\n",
      "20.08% complete\n",
      "24.10% complete\n",
      "28.11% complete\n",
      "32.13% complete\n",
      "36.14% complete\n",
      "40.16% complete\n",
      "44.18% complete\n",
      "48.19% complete\n",
      "52.21% complete\n",
      "56.22% complete\n",
      "60.24% complete\n",
      "64.26% complete\n",
      "68.27% complete\n",
      "72.29% complete\n",
      "76.31% complete\n",
      "80.32% complete\n",
      "84.34% complete\n",
      "88.35% complete\n",
      "92.37% complete\n",
      "96.39% complete\n",
      "100.00% complete\n"
     ]
    }
   ],
   "source": [
    "# Fill in the rest of the data frame with the first entry for each date for a column\n",
    "def populate_data_frame_with_first_entry_on_each_date(column):\n",
    "    output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        column\n",
    "    ] = output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        column\n",
    "    ].iloc[0]\n",
    "\n",
    "    \n",
    "number_of_dates = len(pd.unique(output[\"date\"]))\n",
    "\n",
    "for j, date in enumerate(pd.unique(output[\"date\"])):\n",
    "    # We padded the array with NaNs to make each date have 920 data points\n",
    "    # Find out how many non-NaNs we have. This represents the last real data\n",
    "    # point on each day. E.g. on 2019-01-01 there are 369 real data points\n",
    "    last_non_null_index = output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        \"lake_water_level\"\n",
    "    ].count()\n",
    "\n",
    "    # Get the lake water level on each day as a numpy array\n",
    "    lake_water_level = np.array(\n",
    "        output.loc[\n",
    "            output[\"date\"] == date,\n",
    "            \"lake_water_level\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get the mean and standard deviation of the non-NaN data on each day\n",
    "    mean_lake_water_level = np.mean(lake_water_level[0:last_non_null_index])\n",
    "    std_lake_water_level = np.std(lake_water_level[0:last_non_null_index])\n",
    "\n",
    "    # We are going to populate the NaNs with a randomly sampled array\n",
    "    # with the right standard deviation and mean\n",
    "    filling_array = np.random.normal(\n",
    "        loc=mean_lake_water_level,\n",
    "        scale=std_lake_water_level,\n",
    "        size=max_track_length - last_non_null_index # e.g. 920 - 369 = 551\n",
    "    )\n",
    "\n",
    "    # Fill the NaNs\n",
    "    lake_water_level[last_non_null_index:max_track_length] = filling_array\n",
    "\n",
    "    # Put back into the data frame\n",
    "    output.loc[\n",
    "        output[\"date\"] == date,\n",
    "        \"lake_water_level\"\n",
    "    ] = lake_water_level\n",
    "\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"relative_orbit\")\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"in_situ_lake_water_level\")\n",
    "    populate_data_frame_with_first_entry_on_each_date(\"lake_name\")\n",
    "    \n",
    "    if j % 10 == 0 or j == number_of_dates - 1:\n",
    "        percentage_complete = j/(number_of_dates - 1) * 100.\n",
    "        print(\"%0.02f%% complete\"%(percentage_complete))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f9265e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data frame to csv\n",
    "output.to_csv(\"./processed/imputed_sentinel_a_b_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4befcaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec80390f",
   "metadata": {},
   "source": [
    "# Prepare test/train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2880ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = output.iloc[0:200*920]\n",
    "df_test = output.iloc[201*920::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c5936fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(datain, timestep):\n",
    "    # Get the lake water levels as numpy arrays\n",
    "    lake_water_levels = np.array(datain[\"lake_water_level\"])\n",
    "    in_situ_lake_water_levels = np.array(datain[\"in_situ_lake_water_level\"])\n",
    "    \n",
    "    # Get the number of unique dates. For e.g. in our training data, it's 200.\n",
    "    number_of_dates = len(pd.unique(datain[\"date\"]))\n",
    "    \n",
    "    # Number of windows we can fit into the data\n",
    "    number_of_windows = number_of_dates - (2 * timestep) + 1\n",
    "    \n",
    "    # Sliding window across the data\n",
    "    for d in range(0, number_of_dates - (2 * timestep) + 1):\n",
    "        X_start = d * max_track_length # Starting index\n",
    "        X_end = (d + timestep) * max_track_length # Finishing index\n",
    "        \n",
    "        Y = (d + np.arange(timestep)) * max_track_length # Indices for getting in-situ data\n",
    "        \n",
    "        if d==0:\n",
    "            X_comb = lake_water_levels[X_start:X_end]\n",
    "            Y_comb = in_situ_lake_water_levels[Y]\n",
    "        else:\n",
    "            X_comb = np.append(X_comb, lake_water_levels[X_start:X_end])\n",
    "            Y_comb = np.append(Y_comb, in_situ_lake_water_levels[Y])\n",
    "\n",
    "    # Reshape input and target arrays\n",
    "    X_out = np.reshape(X_comb, (number_of_windows, timestep*max_track_length, 1))\n",
    "    Y_out = np.reshape(Y_comb, (number_of_windows, timestep, 1))\n",
    "    return X_out, Y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f5aae60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = prepare_data(datain=df_train, timestep=5)\n",
    "X_test, Y_test = prepare_data(datain=df_test, timestep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2bf1e",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c0eb4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM\n",
    "model = Sequential(name=\"LSTM-Model\")\n",
    "model.add(\n",
    "    Input(\n",
    "        shape=(X_train.shape[1], X_train.shape[2]),\n",
    "        name=\"Input-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(\n",
    "            units=32,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=False,\n",
    "        ),\n",
    "        name=\"Hidden-LSTM-Encoder-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    RepeatVector(\n",
    "        Y_train.shape[1],\n",
    "        name=\"Repeat-Vector-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(\n",
    "            units=32,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            stateful=False,\n",
    "            return_sequences=True\n",
    "        ),\n",
    "        name=\"Hidden-LSTM-Decoder-Layer\"\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        Dense(\n",
    "            units=1,\n",
    "            activation=\"linear\"\n",
    "        ),\n",
    "        name=\"Output-Layer\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "17a5902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"MeanSquaredError\", \"MeanAbsoluteError\"],\n",
    "    loss_weights=None,\n",
    "    weighted_metrics=None,\n",
    "    run_eagerly=None,\n",
    "    steps_per_execution=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3eeb226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "152/152 [==============================] - 50s 313ms/step - loss: 42886.7344 - mean_squared_error: 42886.7383 - mean_absolute_error: 206.9950\n",
      "Epoch 2/1000\n",
      "152/152 [==============================] - 48s 314ms/step - loss: 37172.8711 - mean_squared_error: 37172.8828 - mean_absolute_error: 192.7729\n",
      "Epoch 3/1000\n",
      "152/152 [==============================] - 48s 317ms/step - loss: 33432.9883 - mean_squared_error: 33432.9883 - mean_absolute_error: 182.8159\n",
      "Epoch 4/1000\n",
      "152/152 [==============================] - 48s 315ms/step - loss: 30125.4902 - mean_squared_error: 30125.4746 - mean_absolute_error: 173.5306\n",
      "Epoch 5/1000\n",
      "152/152 [==============================] - 48s 314ms/step - loss: 27117.8086 - mean_squared_error: 27117.8125 - mean_absolute_error: 164.6299\n",
      "Epoch 6/1000\n",
      "152/152 [==============================] - 48s 315ms/step - loss: 24361.5820 - mean_squared_error: 24361.5703 - mean_absolute_error: 156.0268\n",
      "Epoch 7/1000\n",
      "152/152 [==============================] - 48s 318ms/step - loss: 21829.1914 - mean_squared_error: 21829.1914 - mean_absolute_error: 147.6793\n",
      "Epoch 8/1000\n",
      "152/152 [==============================] - 48s 319ms/step - loss: 19501.4609 - mean_squared_error: 19501.4531 - mean_absolute_error: 139.5640\n",
      "Epoch 9/1000\n",
      "152/152 [==============================] - 48s 317ms/step - loss: 17363.3691 - mean_squared_error: 17363.3730 - mean_absolute_error: 131.6679\n",
      "Epoch 10/1000\n",
      "152/152 [==============================] - 48s 314ms/step - loss: 15402.3486 - mean_squared_error: 15402.3438 - mean_absolute_error: 123.9823\n",
      "Epoch 11/1000\n",
      "152/152 [==============================] - 49s 320ms/step - loss: 13607.3623 - mean_squared_error: 13607.3633 - mean_absolute_error: 116.5022\n",
      "Epoch 12/1000\n",
      "152/152 [==============================] - 49s 322ms/step - loss: 11968.5254 - mean_squared_error: 11968.5234 - mean_absolute_error: 109.2232\n",
      "Epoch 13/1000\n",
      "152/152 [==============================] - 49s 324ms/step - loss: 10476.7363 - mean_squared_error: 10476.7324 - mean_absolute_error: 102.1448\n",
      "Epoch 14/1000\n",
      "152/152 [==============================] - 48s 318ms/step - loss: 9123.4766 - mean_squared_error: 9123.4785 - mean_absolute_error: 95.2665\n",
      "Epoch 15/1000\n",
      "152/152 [==============================] - 48s 316ms/step - loss: 7900.7046 - mean_squared_error: 7900.7065 - mean_absolute_error: 88.5904\n",
      "Epoch 16/1000\n",
      "152/152 [==============================] - 48s 314ms/step - loss: 6800.7275 - mean_squared_error: 6800.7271 - mean_absolute_error: 82.1188\n",
      "Epoch 17/1000\n",
      "152/152 [==============================] - 48s 318ms/step - loss: 5816.1021 - mean_squared_error: 5816.1025 - mean_absolute_error: 75.8561\n",
      "Epoch 18/1000\n",
      " 35/152 [=====>........................] - ETA: 37s - loss: 5267.2539 - mean_squared_error: 5267.2534 - mean_absolute_error: 72.1461"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [215]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data=(X_test, Y_test)\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.virtualenvs/ml-freshwater/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=1,\n",
    "    epochs=1000,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_split=0.2,\n",
    "    # validation_data=(X_test, Y_test)\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=100,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e588b1",
   "metadata": {},
   "source": [
    "# Simplification: take the median on each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e3531f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_output = output.groupby(\"date\").agg(\n",
    "    {\n",
    "        \"date\" : \"first\",\n",
    "        \"lake_name\" : \"first\",\n",
    "        \"relative_orbit\" : \"first\",\n",
    "        \"lake_water_level\" : \"median\",\n",
    "        \"in_situ_lake_water_level\" : \"first\"\n",
    "        # Drop lat/long since it varies for each point\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c65efb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
